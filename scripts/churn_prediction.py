# -*- coding: utf-8 -*-
"""Churn Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vHiaxnsey67WplceLIZH2BjYEF_hOqkm

## Data Overview
"""

# Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# Importing the dataset
dataset = pd.read_csv('Churn_Dataset.csv')
dataset

# Understanding dataset
dataset.info()
dataset.describe(include="all")
dataset.isnull().sum()

"""# Target Variable"""

# Distribution of Target Variable
import seaborn as sns
import matplotlib.pyplot as plt

# Plot the count of churn values
plt.figure(figsize=(6,4))
sns.countplot(x=dataset["Churn Value"], palette="coolwarm")

# Add labels and title
plt.title("Churn Value Distribution")
plt.xlabel("Churn (0 = No, 1 = Yes)")
plt.ylabel("Count")

# Show the plot
plt.show()

dataset["Churn Value"].value_counts()

"""# Feature Variables

Exploratory Data Analysis Plots
"""

#Tenure months VS. Churn (how long customers stay before they churn)
plt.figure(figsize=(8,5))
sns.histplot(dataset, x='Tenure Months', hue='Churn Label', bins=30, kde=True, palette=['blue', 'red'])
plt.title("Tenure Distribution by Churn Status")
plt.xlabel("Tenure (Months)")
plt.ylabel("Count")
plt.legend(title="Churn", labels=["No", "Yes"])
plt.show()

#Monthly Charges Distribution by Churn Status (show if customers with higher or lower monthly charges are more likely to churn)
plt.figure(figsize=(8,5))
sns.boxplot(data=dataset, x='Churn Label', y='Monthly Charges', palette=['blue', 'red'])
plt.title("Monthly Charges vs Churn")
plt.xlabel("Churn Label")
plt.ylabel("Monthly Charges ($)")
plt.show()

#Churn By Contract Type
plt.figure(figsize=(8,5))
sns.countplot(data=dataset, x='Contract', hue='Churn Label', palette=['blue', 'red'])
plt.title("Churn by Contract Type")
plt.xlabel("Contract Type")
plt.ylabel("Count")
plt.legend(title="Churn", labels=["No", "Yes"])
plt.show()

#Churn By Location (Latitude/Longitude)
# Create a scatter plot
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Longitude', y='Latitude', hue='Churn Label', data=dataset, palette='coolwarm', s=100)

# Set plot labels and title
plt.title("Churn Impact by Latitude and Longitude", fontsize=16)
plt.xlabel("Longitude", fontsize=12)
plt.ylabel("Latitude", fontsize=12)

# Display the plot
plt.show()

#Churn By City
# Calculate churn rate by city (percentage of churned customers per city)
churn_rate = dataset.groupby('City')['Churn Value'].mean().reset_index()
churn_rate['churn_rate'] = churn_rate['Churn Value'] * 100  # Convert to percentage

# Plot the churn rate by city
plt.figure(figsize=(10, 6))
sns.barplot(x='City', y='churn_rate', data=churn_rate, palette='coolwarm')

# Set plot labels and title
plt.title("Churn Rate by City", fontsize=16)
plt.xlabel("City", fontsize=12)
plt.ylabel("Churn Rate (%)", fontsize=12)

# Display the plot
plt.show()

#Churn By Gender
# Count the churn status for each gender
churn_by_gender = dataset.groupby(['Gender', 'Churn Label']).size().unstack().reset_index()

# Plot the churn based on gender
churn_by_gender.plot(kind='bar', x='Gender', stacked=True, color=['skyblue', 'salmon'], figsize=(8, 6))

# Set plot labels and title
plt.title("Churn Based on Gender", fontsize=16)
plt.xlabel("Gender", fontsize=12)
plt.ylabel("Number of Customers", fontsize=12)

# Display the plot
plt.show()

#Churn by R/s status
# Count the churn status for with and without partner
churn_by_gender = dataset.groupby(['Partner', 'Churn Label']).size().unstack().reset_index()

# Plot the churn based on r/s status
churn_by_gender.plot(kind='bar', x='Partner', stacked=True, color=['skyblue', 'salmon'], figsize=(8, 6))

# Set plot labels and title
plt.title("Churn Based on Having a Partner", fontsize=16)
plt.xlabel("Partner Present", fontsize=12)
plt.ylabel("Number of Customers", fontsize=12)

# Display the plot
plt.show()

#Churn by Having dependents
# Count the churn status for with and without partner
churn_by_gender = dataset.groupby(['Dependents', 'Churn Label']).size().unstack().reset_index()

# Plot the churn based on r/s status
churn_by_gender.plot(kind='bar', x='Dependents', stacked=True, color=['skyblue', 'salmon'], figsize=(8, 6))

# Set plot labels and title
plt.title("Churn Based on Having Dependents", fontsize=16)
plt.xlabel("Having Dependents", fontsize=12)
plt.ylabel("Number of Customers", fontsize=12)

# Display the plot
plt.show()

#Churn by Senior Citizen
# Count the churn status for with and without partner
churn_by_gender = dataset.groupby(['Senior Citizen', 'Churn Label']).size().unstack().reset_index()

# Plot the churn based on r/s status
churn_by_gender.plot(kind='bar', x='Senior Citizen', stacked=True, color=['skyblue', 'salmon'], figsize=(8, 6))

# Set plot labels and title
plt.title("Churn Based on Senior Citizen", fontsize=16)
plt.xlabel("Senior Citizen", fontsize=12)
plt.ylabel("Number of Customers", fontsize=12)

# Display the plot
plt.show()

#Categorizing Churn Reason
unique_values = dataset['Churn Reason'].unique()

# Print unique values
print(unique_values)

# Define categorization function
def categorize_reason(reason):
    if pd.isna(reason):
        return np.nan
    elif reason in ['Competitor made better offer', 'Competitor had better devices',
                    'Competitor offered higher download speeds', 'Competitor offered more data']:
        return 'Competitor'
    elif reason in ['Moved', 'Deceased']:
        return 'Personal Reasons'
    elif reason in ['Price too high', 'Long distance charges', 'Extra data charges']:
        return 'Price'
    elif reason in ['Product dissatisfaction', 'Network reliability', 'Limited range of services',
                    'Lack of affordable download/upload speed']:
        return 'Product Quality'
    elif reason == 'Service dissatisfaction':
        return 'Service Quality'
    elif reason == 'Lack of self-service on Website':
        return 'Customer Experience'
    elif reason in ['Poor expertise of online support', 'Poor expertise of phone support',
                    'Attitude of service provider', 'Attitude of support person']:
        return 'Customer Service'
    elif reason == "Don't know":
        return 'Unclear/Unspecified'
    else:
        return 'Other'

# Apply function to create the new column in the existing dataset
dataset['categorized_reason'] = dataset['Churn Reason'].apply(categorize_reason)

# Display updated dataset
print(dataset)

#Frequency Distribution of Churn Reason (Categorized)
# Get frequency distribution
frequency_distribution = dataset['categorized_reason'].value_counts()

# Plot bar graph
plt.figure(figsize=(12, 6))
sns.barplot(x=frequency_distribution.index, y=frequency_distribution.values, palette="Blues_r")

# Add labels and title
plt.xlabel("Categorized Reason", fontsize=12)
plt.ylabel("Frequency", fontsize=12)
plt.title("Frequency Distribution of Categorized Churn Reasons", fontsize=14)
plt.xticks(rotation=45, ha='right')

#Clustering based on Lat/Long
from sklearn.cluster import KMeans

# Define number of clusters (adjust as needed)
num_clusters = 5  # Start with 5, then adjust based on visualization
kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)
dataset['location_cluster'] = kmeans.fit_predict(dataset[['Latitude', 'Longitude']])

# Get cluster centers
centers = kmeans.cluster_centers_
plt.figure(figsize=(10, 6))

# Plot scatter points with color based on cluster
sns.scatterplot(data=dataset, x='Longitude', y='Latitude', hue='location_cluster', palette='viridis', alpha=0.6)

# Plot cluster centers
plt.scatter(centers[:, 1], centers[:, 0], c='red', marker='X', s=200, label='Cluster Centers')

# Add labels
plt.xlabel("Longitude")
plt.ylabel("Latitude")
plt.title("K-Means Clustering of Locations")
plt.legend()
plt.show()

#Churn by K Means Cluster (To check if clustering shows any difference)
cluster_churn_counts = dataset.groupby('location_cluster')['Churn Label'].value_counts().unstack()
print(cluster_churn_counts)
# Plot a stacked bar chart
cluster_churn_counts.plot(kind='bar', stacked=True, figsize=(10, 6), colormap='viridis')

# Labels and title
plt.xlabel("Location Cluster")
plt.ylabel("Count")
plt.title("Churn Frequency Distribution by Location Cluster")
plt.xticks(rotation=0)
plt.legend(title="Churn Status")

# Show plot
plt.show()

"""Discard irrelevant variables"""

d_m = dataset.drop(columns=['CustomerID', 'Count','Country','State','City','Zip Code','Lat Long','Latitude','Longitude','Churn Label','Churn Reason','categorized_reason'])
print(d_m)

"""Checking for Missingness"""

print(d_m.isnull().sum())

"""Split Dataset into Numeric and Categorical data"""

d_numeric = d_m[['Tenure Months','Monthly Charges','Total Charges','Churn Score','CLTV']]
d_categorical = d_m[['Gender','Senior Citizen','Partner','Dependents','Phone Service','Multiple Lines','Internet Service','Online Security','Online Backup','Device Protection','Tech Support','Streaming TV','Streaming Movies','Contract','Paperless Billing','Payment Method','Churn Value','location_cluster']]
d_numeric = d_numeric.apply(pd.to_numeric, errors='coerce')
print(d_numeric)

"""# Addressing Numeric Variables

Handling Missingness
"""

print(d_numeric.isnull().sum())
skewness = d_numeric['Total Charges'].skew()
print("Skewness of 'Total Charges':", skewness)

# Impute missing values in 'Total Charges' with the mean
d_numeric['Total Charges'] = d_numeric['Total Charges'].fillna(d_numeric['Total Charges'].mean())

# Verify the changes by checking for missing values
print(d_numeric['Total Charges'].isnull().sum())

"""Addressing Outliers"""

# Calculate the IQR for each numeric column
Q1 = d_numeric.quantile(0.25)
Q3 = d_numeric.quantile(0.75)
IQR = Q3 - Q1
# Define the lower and upper bounds for detecting outliers
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
# Check for outliers in each numeric column
outliers = ((d_numeric < lower_bound) | (d_numeric > upper_bound))
# Calculate the percentage of outliers in each numeric column
outliers_percentage = (outliers.sum() / len(d_numeric)) * 100
# Print the percentage of outliers for each numeric column
print(outliers_percentage)

# Calculate skewness for each numeric column
skewness = d_numeric.skew()

# Print skewness for each column
print(skewness)

d_numeric['Total Charges'] = np.sqrt(d_numeric['Total Charges'])
new_skewness = d_numeric[['Total Charges']].skew()

# Print skewness values
print(new_skewness)

"""# Addressing Categorical Variables"""

# Get the number of unique values for each categorical column
unique_counts = d_categorical.nunique()
# Print the result
print(unique_counts)
for column in d_categorical.columns:
    print(f"Unique values in {column}:")
    print(d_categorical[column].unique())
    print("\n")

# Filter the dataset for records where 'Internet Service' is 'No'
no_internet_service = d_m[d_m['Internet Service'] == 'No']

# Display the filtered records
print(no_internet_service)

"""Encoding Variables"""

d_categorical['no_internet_service'] = (d_categorical['Internet Service'] == 'No').astype(int)
d_categorical['no_phone_service'] = (d_categorical['Phone Service'] == 'No').astype(int)

print(d_categorical)

d_categorical['Phone Service'] = (d_categorical['Phone Service'] == 'Yes').astype(int)
d_categorical['Multiple Lines'] = (d_categorical['Multiple Lines'] == 'Yes').astype(int)
d_categorical['Online Security'] = (d_categorical['Online Security'] == 'Yes').astype(int)
d_categorical['Online Backup'] = (d_categorical['Online Backup'] == 'Yes').astype(int)
d_categorical['Device Protection'] = (d_categorical['Device Protection'] == 'Yes').astype(int)
d_categorical['Tech Support'] = (d_categorical['Tech Support'] == 'Yes').astype(int)
d_categorical['Streaming TV'] = (d_categorical['Streaming TV'] == 'Yes').astype(int)
d_categorical['Streaming Movies'] = (d_categorical['Streaming Movies'] == 'Yes').astype(int)
d_categorical['Senior Citizen'] = (d_categorical['Senior Citizen'] == 'Yes').astype(int)
d_categorical['Gender'] = (d_categorical['Gender'] == 'Male').astype(int)
d_categorical['Partner'] = (d_categorical['Partner'] == 'Yes').astype(int)
d_categorical['Dependents'] = (d_categorical['Dependents'] == 'Yes').astype(int)
d_categorical['Paperless Billing'] = (d_categorical['Paperless Billing'] == 'Yes').astype(int)

d_categorical = pd.get_dummies(d_categorical, columns=['Internet Service', 'Contract', 'Payment Method'], dtype=int)

print(d_categorical)

d_categorical.drop(columns=['Internet Service_No'], inplace=True)

# Get the number of unique values for each categorical column
unique_counts = d_categorical.nunique()
# Print the result
print(unique_counts)
for column in d_categorical.columns:
    print(f"Unique values in {column}:")
    print(d_categorical[column].unique())
    print("\n")

"""# Scaling"""

from sklearn.preprocessing import MinMaxScaler

# Initialize the scaler
scaler = MinMaxScaler()

# Apply scaling to the numeric dataset
d_numeric_scaled = scaler.fit_transform(d_numeric)

# Convert the scaled array back to a DataFrame
d_numeric_scaled = pd.DataFrame(d_numeric_scaled, columns=d_numeric.columns)

"""Addressing Collinearity"""

# Calculate the correlation matrix
corr_matrix = d_numeric.corr()

# Plot a heatmap of the correlation matrix
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Matrix')
plt.show()

d_numeric_scaled = d_numeric_scaled.drop(columns=['Total Charges'])

d_cat_feature = d_categorical.drop(columns=['Churn Value'])

#Categorical Variables
from scipy.stats import chi2_contingency

# Step 1: Define a function to perform Chi-Square test and return the p-value
def chi_square_p_value(x, y):
    contingency_table = pd.crosstab(x, y)
    chi2, p, dof, expected = chi2_contingency(contingency_table)
    return p

# Step 2: Select categorical columns
categorical_cols = d_cat_feature.columns

# Step 3: Create an empty DataFrame to store p-values
p_values_matrix = pd.DataFrame(index=categorical_cols, columns=categorical_cols)

# Step 4: Perform Chi-Square test for each pair of categorical variables and populate the p-values matrix
for col1 in categorical_cols:
    for col2 in categorical_cols:
        if col1 != col2:
            p_values_matrix.loc[col1, col2] = chi_square_p_value(d_categorical[col1], d_categorical[col2])
        else:
            p_values_matrix.loc[col1, col2] = 1  # p-value of 1 for the same column pair

# Step 5: Convert the p-values matrix to float type
p_values_matrix = p_values_matrix.astype(float)

# Step 6: Plot heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(p_values_matrix, annot=True, cmap="coolwarm", fmt=".2f", vmin=0, vmax=1)
plt.title("Chi-Square Test p-values Heatmap")
plt.show()

print(d_cat_feature.columns)

print(d_cat_feature.describe(include='all'))

d_categorical = d_categorical.drop(columns=['no_phone_service', 'Phone Service','Contract_Two year','Contract_Month-to-month','Contract_One year','Payment Method_Bank transfer (automatic)','Payment Method_Credit card (automatic)','Payment Method_Electronic check','Payment Method_Mailed check','no_internet_service','Internet Service_DSL','Internet Service_Fiber optic'])

# Select specific columns to add
columns_to_add = ['Phone Service', 'Internet Service','Contract','Payment Method']

# Concatenate selected columns
d_categorical = pd.concat([d_categorical, dataset[columns_to_add]], axis=1)

"""Split dataset into training and test set"""

df_combined = pd.concat([d_numeric_scaled, d_categorical], axis=1)

print(df_combined.head())

from sklearn.model_selection import train_test_split

# Example dataset (X - features, y - target)
X = df_combined.drop('Churn Value', axis=1)  # Features (drop target column)
y = df_combined['Churn Value']  # Target variable

# Split dataset into training and test sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)



!pip install category_encoders
import category_encoders as ce

#Target Encoding
import category_encoders as ce
encoder = ce.TargetEncoder(cols=['Payment Method', 'Phone Service', 'Internet Service', 'Contract'])
X_train_encoded = encoder.fit_transform(X_train, y_train)
X_test_encoded = encoder.transform(X_test)

"""Applying SMOTE on Training Set"""

!pip install imbalanced-learn
from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_encoded, y_train)
from collections import Counter
print("Class distribution before SMOTE:", Counter(y_train))
print("Class distribution after SMOTE:", Counter(y_train_balanced))

"""# Logistic Regression

Model
"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
# Initialize the model
log_reg = LogisticRegression(random_state=42)

# Train the model on the balanced dataset
log_reg.fit(X_train_balanced, y_train_balanced)

# Make predictions on the test set
y_pred = log_reg.predict(X_test_encoded)

# Print evaluation metrics
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test,y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

"""Plot"""

plt.figure(figsize=(10, 6))

# X-axis: Sample index
x_index = np.arange(len(y_test))

# Correctly predicted points (Green)
correct = y_test == y_pred
plt.scatter(x_index[correct], y_test[correct], color='green', label='Correct Prediction', alpha=0.6, marker='o')

# Incorrectly predicted points (Red)
incorrect = y_test != y_pred
plt.scatter(x_index[incorrect], y_test[incorrect], color='red', label='Incorrect Prediction', alpha=0.6, marker='x')

plt.xlabel("Sample Index")
plt.ylabel("Class (0 or 1)")
plt.yticks([0, 1])  # Only show 0 and 1 on Y-axis
plt.title("Model Predictions: Correct vs. Incorrect")
plt.legend()
plt.grid(alpha=0.3)
plt.show()

"""AUC-ROC"""

from sklearn.metrics import roc_curve, roc_auc_score

# Get predicted probabilities (for ROC, we need probabilities, not class labels)
y_probs = log_reg.predict_proba(X_test_encoded)[:, 1]  # Probabilities for class 1

# Compute ROC curve
fpr, tpr, _ = roc_curve(y_test, y_probs)

# Compute AUC score
auc_score = roc_auc_score(y_test, y_probs)

# Plot ROC Curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', label=f"AUC = {auc_score:.2f}")
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Diagonal baseline

plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.grid(alpha=0.3)
plt.show()

# Print AUC Score
print(f"AUC Score: {auc_score:.4f}")

"""Feature Importance"""

# Get the feature importance from the coefficients
log_reg_feature_importance = np.abs(log_reg.coef_[0])

# Create a DataFrame for better visualization
feature_importance_log_reg = pd.DataFrame({
    'Feature': X_train_balanced.columns,
    'Importance': log_reg_feature_importance
})

# Sort features by importance
feature_importance_log_reg = feature_importance_log_reg.sort_values(by='Importance', ascending=False)

# Print the feature importance
print("Logistic Regression Feature Importance:\n", feature_importance_log_reg)

"""# Random Forest

Model
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Initialize the model
rf_clf = RandomForestClassifier(random_state=42)

# Train the model on the balanced dataset
rf_clf.fit(X_train_balanced, y_train_balanced)

# Make predictions on the test set
y_pred_rf = rf_clf.predict(X_test_encoded)

# Print evaluation metrics
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Classification Report:\n", classification_report(y_test, y_pred_rf))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_rf))

"""Plot"""

# Compare predictions with the actual labels
correct_predictions = (y_pred_rf == y_test)
incorrect_predictions = (y_pred_rf != y_test)
# Create a scatter plot
plt.figure(figsize=(8, 6))
# Plot correct predictions in green
plt.scatter(np.where(correct_predictions)[0], y_test[correct_predictions], color='green', label='Correct Predictions', alpha=0.6)
# Plot incorrect predictions in red
plt.scatter(np.where(incorrect_predictions)[0], y_test[incorrect_predictions], color='red', label='Incorrect Predictions', alpha=0.6)
# Add labels and title
plt.xlabel('Sample Index')
plt.ylabel('Actual Labels')
plt.title('Correct vs Incorrect Predictions')
# Set x-axis to have no decimal points
plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x)}'))
# Add legend
plt.legend()
# Show the plot
plt.show()

"""AUC - ROC"""

# Get the probabilities for the positive class (class 1)
y_prob_rf = rf_clf.predict_proba(X_test_encoded)[:, 1]

# Calculate AUC
auc_score = roc_auc_score(y_test, y_prob_rf)
print("AUC-ROC:", auc_score)

# Compute ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_prob_rf)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {auc_score:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Diagonal line
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.show()
# Calculate the AUC-ROC score
auc_score = roc_auc_score(y_test, y_prob_rf)
# Print the AUC-ROC value
print("AUC-ROC Score:", auc_score)

"""Feature Importance"""

# Get feature importance from Random Forest
feature_importance_rf = rf_clf.feature_importances_

# Create a DataFrame for better visualization
feature_importance_rf_df = pd.DataFrame({
    'Feature': X_train_balanced.columns,
    'Importance': feature_importance_rf
})

# Sort features by importance
feature_importance_rf_df = feature_importance_rf_df.sort_values(by='Importance', ascending=False)

# Print the feature importance
print("Random Forest Feature Importance:\n", feature_importance_rf_df)

"""# Neural Networks

Model
"""

from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Initialize the model
nn_model = MLPClassifier(random_state=42, max_iter=500)

# Train the model on the balanced dataset
nn_model.fit(X_train_balanced, y_train_balanced)

# Make predictions on the test set
y_pred_nn = nn_model.predict(X_test_encoded)

# Print evaluation metrics
print("Accuracy:", accuracy_score(y_test, y_pred_nn))
print("Classification Report:\n", classification_report(y_test, y_pred_nn))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_nn))

"""Plot"""

# Compare predictions with the actual labels
correct_predictions = (y_pred_nn == y_test)
incorrect_predictions = (y_pred_nn != y_test)
# Create a scatter plot
plt.figure(figsize=(8, 6))
# Plot correct predictions in green
plt.scatter(np.where(correct_predictions)[0], y_test[correct_predictions], color='green', label='Correct Predictions', alpha=0.6)
# Plot incorrect predictions in red
plt.scatter(np.where(incorrect_predictions)[0], y_test[incorrect_predictions], color='red', label='Incorrect Predictions', alpha=0.6)
# Add labels and title
plt.xlabel('Sample Index')
plt.ylabel('Actual Labels')
plt.title('Correct vs Incorrect Predictions')
# Set x-axis to have no decimal points
plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x)}'))
# Add legend
plt.legend()
# Show the plot
plt.show()

"""AUC-ROC"""

# Get the probabilities for the positive class (class 1)
y_prob_nn = nn_model.predict_proba(X_test_encoded)[:, 1]

# Compute ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_prob_nn)

# Calculate AUC-ROC
auc_score_nn = roc_auc_score(y_test, y_prob_nn)
print("AUC-ROC Score:", auc_score_nn)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {auc_score_nn:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Diagonal line
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.show()

"""Feature Importance"""

# Get the feature importance from the first layer weights
nn_feature_importance = np.abs(nn_model.coefs_[0]).mean(axis=1)

# Create a DataFrame for better visualization
feature_importance_nn_df = pd.DataFrame({
    'Feature': X_train_balanced.columns,
    'Importance': nn_feature_importance
})

# Sort features by importance
feature_importance_nn_df = feature_importance_nn_df.sort_values(by='Importance', ascending=False)

# Print the feature importance
print("Neural Network Feature Importance:\n", feature_importance_nn_df)